From: Alaa Hleihel <alaa@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/infiniband/hw/mlx4/main_exp.c

Change-Id: Iff14e3a9bec1da873cf6000a3e2b51fb916cfc20
---
 drivers/infiniband/hw/mlx4/main_exp.c | 58 +++++++++++++++++++++++++++++++++++
 1 file changed, 58 insertions(+)

--- a/drivers/infiniband/hw/mlx4/main_exp.c
+++ b/drivers/infiniband/hw/mlx4/main_exp.c
@@ -143,6 +143,60 @@ int mlx4_ib_exp_ioctl(struct ib_ucontext
 	return ret;
 }
 
+#ifdef HAVE_MM_STRUCT_FREE_AREA_CACHE 
+unsigned long mlx4_ib_exp_get_unmapped_area(struct file *file,
+					    unsigned long addr,
+					    unsigned long len, unsigned long pgoff,
+					    unsigned long flags)
+{
+	struct mm_struct *mm;
+	struct vm_area_struct *vma;
+	unsigned long start_addr;
+	unsigned long page_size_order;
+	unsigned long  command;
+
+	mm = current->mm;
+	if (addr)
+		return current->mm->get_unmapped_area(file, addr, len,
+						pgoff, flags);
+
+	/* Last 8 bits hold the  command others are data per that command */
+	command = pgoff & MLX4_IB_EXP_MMAP_CMD_MASK;
+	if (command != MLX4_IB_EXP_MMAP_GET_CONTIGUOUS_PAGES)
+		return current->mm->get_unmapped_area(file, addr, len,
+						pgoff, flags);
+	page_size_order = pgoff >> MLX4_IB_EXP_MMAP_CMD_BITS;
+	/* code is based on the huge-pages get_unmapped_area code */
+	start_addr = mm->free_area_cache;
+
+	if (len <= mm->cached_hole_size)
+		start_addr = TASK_UNMAPPED_BASE;
+
+
+full_search:
+	addr = ALIGN(start_addr, 1 << page_size_order);
+
+	for (vma = find_vma(mm, addr); ; vma = vma->vm_next) {
+		/* At this point:  (!vma || addr < vma->vm_end). */
+		if (TASK_SIZE - len < addr) {
+			/*
+			 * Start a new search - just in case we missed
+			 * some holes.
+			 */
+			if (start_addr != TASK_UNMAPPED_BASE) {
+				start_addr = TASK_UNMAPPED_BASE;
+				goto full_search;
+			}
+			return -ENOMEM;
+		}
+
+		if (!vma || addr + len <= vma->vm_start)
+			return addr;
+		addr = ALIGN(vma->vm_end, 1 << page_size_order);
+	}
+}
+#endif
+
 int mlx4_ib_exp_uar_mmap(struct ib_ucontext *context, struct vm_area_struct *vma,
 			    unsigned long  command)
 {
@@ -184,7 +238,9 @@ int mlx4_ib_exp_uar_mmap(struct ib_ucont
 		return -EAGAIN;
 	}
 
+#if defined(HAVE_PUT_TASK_STRUCT_EXPORTED) && defined(HAVE_GET_TASK_PID_EXPORTED) && defined(HAVE_GET_PID_TASK_EXPORTED)
 	mlx4_ib_set_vma_data(vma, &uar->hw_bar_info[HW_BAR_DB]);
+#endif
 	mutex_lock(&mucontext->user_uar_mutex);
 	list_add(&uar->list, &mucontext->user_uar_list);
 	mutex_unlock(&mucontext->user_uar_mutex);
@@ -229,6 +285,8 @@ int mlx4_ib_exp_bf_mmap(struct ib_uconte
 			       PAGE_SIZE, vma->vm_page_prot))
 		return -EAGAIN;
 
+#if defined(HAVE_PUT_TASK_STRUCT_EXPORTED) && defined(HAVE_GET_TASK_PID_EXPORTED) && defined(HAVE_GET_PID_TASK_EXPORTED)
 	mlx4_ib_set_vma_data(vma, &uar->hw_bar_info[HW_BAR_BF]);
+#endif
 	return 0;
 }
